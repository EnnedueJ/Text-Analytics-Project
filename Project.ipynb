{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34886, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('wiki_movie_plots_deduped.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28803, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['Genre'] != 'unknown']\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1903</td>\n",
       "      <td>The Great Train Robbery</td>\n",
       "      <td>American</td>\n",
       "      <td>Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>western</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Great_Train_...</td>\n",
       "      <td>The film opens with two bandits breaking into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1904</td>\n",
       "      <td>The Suburbanite</td>\n",
       "      <td>American</td>\n",
       "      <td>Wallace McCutcheon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>comedy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Suburbanite</td>\n",
       "      <td>The film is about a family who move to the sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1906</td>\n",
       "      <td>Dream of a Rarebit Fiend</td>\n",
       "      <td>American</td>\n",
       "      <td>Wallace McCutcheon and Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>short</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Dream_of_a_Rareb...</td>\n",
       "      <td>The Rarebit Fiend gorges on Welsh rarebit at a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1906</td>\n",
       "      <td>From Leadville to Aspen: A Hold-Up in the Rockies</td>\n",
       "      <td>American</td>\n",
       "      <td>Francis J. Marion and Wallace McCutcheon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>short action/crime western</td>\n",
       "      <td>https://en.wikipedia.org/wiki/From_Leadville_t...</td>\n",
       "      <td>The film features a train traveling through th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1906</td>\n",
       "      <td>Kathleen Mavourneen</td>\n",
       "      <td>American</td>\n",
       "      <td>Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>short film</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kathleen_Mavourn...</td>\n",
       "      <td>Irish villager Kathleen is a tenant of Captain...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Release Year                                              Title  \\\n",
       "6           1903                            The Great Train Robbery   \n",
       "7           1904                                    The Suburbanite   \n",
       "10          1906                           Dream of a Rarebit Fiend   \n",
       "11          1906  From Leadville to Aspen: A Hold-Up in the Rockies   \n",
       "12          1906                                Kathleen Mavourneen   \n",
       "\n",
       "   Origin/Ethnicity                                  Director Cast  \\\n",
       "6          American                           Edwin S. Porter  NaN   \n",
       "7          American                        Wallace McCutcheon  NaN   \n",
       "10         American    Wallace McCutcheon and Edwin S. Porter  NaN   \n",
       "11         American  Francis J. Marion and Wallace McCutcheon  NaN   \n",
       "12         American                           Edwin S. Porter  NaN   \n",
       "\n",
       "                         Genre  \\\n",
       "6                      western   \n",
       "7                       comedy   \n",
       "10                       short   \n",
       "11  short action/crime western   \n",
       "12                  short film   \n",
       "\n",
       "                                            Wiki Page  \\\n",
       "6   https://en.wikipedia.org/wiki/The_Great_Train_...   \n",
       "7       https://en.wikipedia.org/wiki/The_Suburbanite   \n",
       "10  https://en.wikipedia.org/wiki/Dream_of_a_Rareb...   \n",
       "11  https://en.wikipedia.org/wiki/From_Leadville_t...   \n",
       "12  https://en.wikipedia.org/wiki/Kathleen_Mavourn...   \n",
       "\n",
       "                                                 Plot  \n",
       "6   The film opens with two bandits breaking into ...  \n",
       "7   The film is about a family who move to the sub...  \n",
       "10  The Rarebit Fiend gorges on Welsh rarebit at a...  \n",
       "11  The film features a train traveling through th...  \n",
       "12  Irish villager Kathleen is a tenant of Captain...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2264"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Genre'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1. dictionary-based conversion readacting Wikipedia's Film genre page:\n",
    "\n",
    "conversion_dict = {\n",
    "    \"action\": [\"disaster\", \"martial arts\", \"spy\", \"superhero\", \"wuxia\",\"action\",\"masala\",\"espionage\",\"arts\"],\n",
    "    \"adventure\": [\"pirate\", \"swashbuckler\", \"samurai\"],\n",
    "    \"animation\": [\"cgi\", \"cutout\", \"live-action animated film\", \"stop motion\", \"animated\", \"computer-animated\", \"anime\"],\n",
    "    \"comedy\": [\"buddy\", \"mockumentary\", \"parody\", \"slapstick\"],\n",
    "    \"drama\": [\"docudrama\", \"melodrama\", \"biodrama\", \"bio-drama\"],\n",
    "    \"historical\": [\"history\", \"historic\", \"alternate history\", \"period\", \"period piece\", \"biopic\", \"bio-pic\", \"biographical\"],\n",
    "    \"horror\": [\"ghost\", \"monster\", \"vampire\", \"werewolf\", \"slash\", \"splatter\", \"zombie\", \"j-horror\",\"supernatural\"],\n",
    "    \"science fiction\": [\"dystopian\", \"dystopia\", \"post-apocalyptic\", \"steampunk\", \"tech noir\", \"utopian\", \"science-fiction\", \"scifi\", \"sci-fi\", \"space\", \"tokusatsu\",\"fiction\"],\n",
    "    \"thriller\": [\"mystery\", \"detective\", \"crime\",\"suspense\"],\n",
    "    \"musical\": [\"operetta\"],\n",
    "    \"romance\": [\"love\",\"romantic\"],\n",
    "    \"western\": [\"cowboy\"],\n",
    "    \"documentary\": [\"pseudo-documentary\"],\n",
    "    \"fantasy\":[],\n",
    "    \"sport\":[\"sports\",\"races\",\"dance\",\"biker\"],\n",
    "    \"war\":['ii','i'],\n",
    "    \"erotic\":['ero','adult','erotic','sexploitation'],\n",
    "    \"social\":['socio','costume']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "#preprocessing function helper for genres reduction\n",
    "def genres_preprocessing(genres_dict, genre):\n",
    "    stop = ['film','short']\n",
    "    for w in stop:\n",
    "        if w in genre:\n",
    "            genre = genre.replace(w,'').strip()\n",
    "        \n",
    "    \n",
    "    splitted = re.split(\"[,/]\", genre)\n",
    "    if len(splitted) != 1:\n",
    "        genre = splitted[0]\n",
    "        \n",
    "    splitted = re.split(\"[-—–]\", genre)\n",
    "    if any(item in genres_dict.keys() for item in splitted):\n",
    "    #if splitted[0] in genres_dict.keys():\n",
    "        genre = splitted[0]\n",
    "    \n",
    "    splitted = re.split(\" \", genre.rstrip())\n",
    "    if len(splitted) != 1:\n",
    "        genre = splitted[-1]\n",
    "        \n",
    "    for key in genres_dict.keys():\n",
    "        if genre.rstrip() in genres_dict[key]:\n",
    "            genre = key\n",
    "        \n",
    "    return genre.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Genre2'] = df['Genre']\n",
    "df['Genre2'] = df['Genre2'].apply(lambda x: genres_preprocessing(conversion_dict, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df['Genre2'].value_counts()\n",
    "to_remove = counts[counts < 50].index\n",
    "\n",
    "df = df[~df.Genre2.isin(to_remove)]\n",
    "\n",
    "drop_id = df[df.Plot.apply(lambda x: len(x) < 25)].index\n",
    "df.drop(drop_id, inplace=True)\n",
    "\n",
    "df = df[df['Genre2'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#g = df.groupby(\"Genre2\")\n",
    "#new_df = g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['western',\n",
       " 'animation',\n",
       " 'science fiction',\n",
       " 'adventure',\n",
       " 'musical',\n",
       " 'war',\n",
       " 'noir',\n",
       " 'family',\n",
       " 'fantasy',\n",
       " 'historical',\n",
       " 'biography',\n",
       " 'social',\n",
       " 'documentary',\n",
       " 'serial',\n",
       " 'sport']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc = df['Genre2'].value_counts()\n",
    "genres_to_fetch = vc[vc < 1000].index.tolist()\n",
    "genres_to_fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_links(src, stw=\"/\", genre=\"\"):\n",
    "    links = []\n",
    "    soup = BeautifulSoup(src)\n",
    "    for link in soup.find_all('a'):\n",
    "        href = link.get('href')\n",
    "        if href and href.startswith(stw) and genre.replace(\" \",\"_\") in href.lower():\n",
    "            links.append(href)\n",
    "            \n",
    "    return links\n",
    "\n",
    "def request_links(base, in_links):\n",
    "    out_links = []\n",
    "    if type(in_links) == list:\n",
    "        response = [ requests.get(base+link).text for link in set(in_links) ]\n",
    "        for res in response:\n",
    "            out_links.extend(get_links(res))\n",
    "\n",
    "    else:\n",
    "        response = requests.get(base+in_links).text\n",
    "        out_links.extend(get_links(response))\n",
    "        \n",
    "    return out_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetching_plot(link):\n",
    "    film_dict = dict()\n",
    "    html = requests.get(link).text\n",
    "    soup = BeautifulSoup(html)\n",
    "    if soup.find(\"span\", {\"id\":\"Plot\"}):\n",
    "        title = soup.find(\"h1\", {\"id\":\"firstHeading\"}).text\n",
    "        print(title)\n",
    "        plot_span = soup.find(\"span\", {\"id\":\"Plot\"})\n",
    "        obj = plot_span.find_parent()\n",
    "        plot = \"\"\n",
    "        while True:\n",
    "            obj = obj.next_sibling\n",
    "            if obj.name not in ['p','h2']:\n",
    "                continue\n",
    "            elif obj.name == 'p':\n",
    "                plot += obj.text.strip('\\n')\n",
    "            elif obj.name == 'h2':\n",
    "                break\n",
    "                \n",
    "        return title, plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "from functools import partial\n",
    "\n",
    "films_dict = dict()\n",
    "\n",
    "def plot_scraper(genre, link):\n",
    "    f_link = \"https://en.wikipedia.org\"+link\n",
    "    title, plot = fetching_plot(f_link) or (None, None)\n",
    "    films_dict[title] = plot\n",
    "    time.sleep(1)\n",
    "    \n",
    "        \n",
    "def set_up_threads(links, genre):\n",
    "    with ThreadPoolExecutor(max_workers=6) as executor:\n",
    "        return executor.map(partial(plot_scraper,genre),\n",
    "                            links,\n",
    "                            timeout = 60)    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"https://en.wikipedia.org\"\n",
    "genres_link = \"https://en.wikipedia.org/wiki/Template:Films_by_genre_sidebar\"\n",
    "\n",
    "main_res = requests.get(genres_link).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WESTERN\n",
      "The Great Train Robbery (1903 film)\n",
      "The Comancheros (film)\n",
      "Kidnapping by Indians\n",
      "The Great Train Robbery (1903 film)\n",
      "Kit Carson (1903 film)\n",
      "The Pioneers (1903 film)\n",
      "Bushranging in North Queensland\n",
      "The Hold-Up of the Leadville Stage\n",
      "The Little Train Robbery\n",
      "The Train Wreckers\n",
      "From Leadville to Aspen: A Hold-Up in the Rockies\n",
      "The Story of the Kelly Gang\n",
      "The Fight for Freedom\n",
      "The Cowboy Millionaire (1909 film)\n",
      "The Last Drop of Water\n",
      "Algie the Miner\n",
      "Geronimo's Last Raid\n",
      "The Girl and Her Trust\n",
      "The Battle at Elderbush Gulch\n",
      "Her Grave Mistake\n",
      "A Miner's Romance\n",
      "A Ranch Romance\n",
      "Rose of the Rancho\n",
      "The Squaw Man (1914 film)\n",
      "The Tragedy of Whispering Creek\n",
      "The Desert Breed\n",
      "The Girl of the Golden West (1915 film)\n",
      "Accusing Evidence\n",
      "The Committee on Credentials\n",
      "Hell's Hinges\n",
      "Liberty (serial)\n",
      "Love's Lariat\n",
      "The Return of Draw Egan\n",
      "A 44-Calibre Mystery\n",
      "The Bad Man of Cheyenne\n",
      "The Empty Gun\n",
      "The Fighting Trail\n",
      "A Marked Man\n",
      "The Narrow Trail\n",
      "The Silent Man (film)\n",
      "Six-Shooter Justice\n",
      "Straight Shooting\n",
      "Wild and Woolly (1917 film)\n",
      "The Grand Passion\n",
      "Bucking Broadway\n",
      "Hell Bent (film)\n",
      "Out West (1918 film)\n",
      "Revenge (1918 film)\n",
      "Riddle GawneRiders of the Purple Sage\n",
      "\n",
      "The Squaw Man (1918 film)The Scarlet Drop\n",
      "\n",
      "Three Mounted Men\n",
      "A Woman's Fool\n",
      "Ace of the SaddleBare Fists\n",
      "\n",
      "A Fight for Love\n",
      "A Gun Fightin' Gentleman\n",
      "The Outcasts of Poker Flat (1919 film)\n",
      "Roped\n",
      "Rustlers (1919 film)\n",
      "Rustlers (1919 film)\n",
      "Scarlet Days\n",
      "The Wilderness Trail\n",
      "Bullet Proof (1920 film)\n",
      "Just Pals\n",
      "The Last of the Mohicans (1920 American film)\n",
      "Lone Hand Wilson\n",
      "The Mark of Zorro (1920 film)\n",
      "Overland Red\n",
      "Robbery Under Arms (1920 film)\n",
      "Ruth of the Rockies\n",
      "Sundown Slim\n"
     ]
    }
   ],
   "source": [
    "for genre in genres_to_fetch:\n",
    "    genre_links = get_links(main_res, \"/wiki/List\", genre)\n",
    "    for link in genre_links:\n",
    "        genre_sublinks = request_links(base, link)\n",
    "        if \"Lists\" in link:\n",
    "            final_genre_sublinks = []\n",
    "            print(genre.upper())\n",
    "            for fl in genre_sublinks:\n",
    "                genre_to_match = genre.title() if genre == 'western' else genre.replace(\" \", \"_\")\n",
    "                genre_to_match = \"List_of_\"+genre_to_match+\"_films\"\n",
    "                if genre_to_match in fl:\n",
    "                    real_fl = request_links(base, fl)\n",
    "                    final_genre_sublinks.extend(real_fl)\n",
    "            set_up_threads(final_genre_sublinks, genre)\n",
    "        else:\n",
    "            print(genre.upper())\n",
    "            set_up_threads(genre_sublinks, genre)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "films_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetching_plot(link):\n",
    "    film_dict = dict()\n",
    "    html = requests.get(link).text\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    # plot fetching\n",
    "    if soup.find(\"span\", {\"id\":\"Plot\"}):\n",
    "        title = soup.find(\"h1\", {\"id\":\"firstHeading\"}).text\n",
    "        print(title)\n",
    "        plot_span = soup.find(\"span\", {\"id\":\"Plot\"})\n",
    "        obj = plot_span.find_parent()\n",
    "        plot = \"\"\n",
    "        while True:\n",
    "            obj = obj.next_sibling\n",
    "            if obj.name not in ['p','h2']:\n",
    "                continue\n",
    "            elif obj.name == 'p':\n",
    "                plot += obj.text.strip('\\n')\n",
    "            elif obj.name == 'h2':\n",
    "                break\n",
    "                \n",
    "    if soup.find(\"span\", {\"id\":\"Cast\"}):\n",
    "        cast_span = soup.find(\"span\", {\"id\": \"Cast\"})\n",
    "        obj = cast_span.find_parent()\n",
    "        cast = \"\"\n",
    "        while True:\n",
    "            obj = obj.next_sibling\n",
    "            if type(obj) != None:\n",
    "                if obj.name not in ['ul', 'li']:\n",
    "                    continue\n",
    "                elif obj.name == 'ul':\n",
    "                    print(\"test\"+obj.name)\n",
    "                    cast += obj.text.strip('li')\n",
    "                elif obj.name == 'h2':\n",
    "                    break\n",
    "            \n",
    "    return title, plot, cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "from functools import partial\n",
    "\n",
    "films_dict = dict()\n",
    "\n",
    "def plot_scraper(genre, link):\n",
    "    f_link = \"https://en.wikipedia.org\"+link\n",
    "    title, plot, cast = fetching_plot(f_link) or (None, None, None)\n",
    "    films_dict[title] = plot, genre, cast\n",
    "    time.sleep(1)\n",
    "    \n",
    "        \n",
    "def set_up_threads(links, genre):\n",
    "    with ThreadPoolExecutor(max_workers=6) as executor:\n",
    "        return executor.map(partial(plot_scraper,genre),\n",
    "                            links,\n",
    "                            timeout = 60) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good Morning (1959 film)\n",
      "testul\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7028/871121120.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_link\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"/wiki/Good_Morning_(1959_film)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot_scraper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"comedy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_link\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7028/562506357.py\u001b[0m in \u001b[0;36mplot_scraper\u001b[1;34m(genre, link)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_scraper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mf_link\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://en.wikipedia.org\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetching_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_link\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mfilms_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7028/2589519708.py\u001b[0m in \u001b[0;36mfetching_plot\u001b[1;34m(link)\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_sibling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'ul'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'li'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'ul'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "test_link = \"/wiki/Good_Morning_(1959_film)\"\n",
    "plot_scraper(\"comedy\", test_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "films_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['Plot'].values\n",
    "y = df['Genre2'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21029, 21029, 7010, 7010)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(y_train),len(X_test),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc_counter = 0\n",
    "def reset_counter():\n",
    "  global doc_counter\n",
    "  doc_counter = 0\n",
    "\n",
    "def increase_counter():\n",
    "  global doc_counter\n",
    "  doc_counter += 1\n",
    "  if doc_counter % 100 == 0:\n",
    "    print(doc_counter)\n",
    "\n",
    "def spacy_nlp_tokenizer(text):\n",
    "    increase_counter()\n",
    "        \n",
    "    # we use spacy for main nlp tasks\n",
    "    doc = nlp(text)\n",
    "    # lemmatized tokens, skipping stopwords\n",
    "    lemmas = ['LEMMA_'+token.lemma_ for token in doc if not token.is_stop]\n",
    "    # entity_types\n",
    "    entity_types = ['NER_'+token.ent_type_ for token in doc if token.ent_type_]\n",
    "\n",
    "    # in case an entity linker is available, we can use it do put actual entities as\n",
    "    # features, e.g. Queen Elizabeth, Elizabeth II, Her Majesty -> KB2912\n",
    "    # see https://spacy.io/usage/training#entity-linker\n",
    "    # entities = ['ENT_'+token.ent_kb_id_ for token in doc if token.ent_kb_id_]\n",
    "\n",
    "    # we use a simple nltk function to create ngrams\n",
    "    lemma_bigrams = ['BI_'+p1+'_'+p2 for p1,p2 in nltk.ngrams(lemmas,2)]\n",
    "    lemma_trigrams = ['TRI_'+p1+'_'+p2+'_'+p3 for p1,p2,p3 in nltk.ngrams(lemmas,3)]\n",
    "\n",
    "    all_tokens = list()\n",
    "    all_tokens.extend(lemmas)\n",
    "    all_tokens.extend(lemma_bigrams)\n",
    "    all_tokens.extend(lemma_trigrams)\n",
    "    all_tokens.extend(entity_types)\n",
    "    return all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9c536223080b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspacy_nlp_tokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_train_tok\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_test_tok\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1201\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1204\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-a11f6cc53fea>\u001b[0m in \u001b[0;36mspacy_nlp_tokenizer\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# we use spacy for main nlp tasks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[1;31m# lemmatized tokens, skipping stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mlemmas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'LEMMA_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m    997\u001b[0m                 \u001b[0merror_handler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_error_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m                 \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m                 \u001b[1;31m# This typically happens if a component is not initialized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m         \"\"\"\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfinish_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\ml\\tb_framework.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     step_model = ParserStepModel(\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\ml\\parser_model.pyx\u001b[0m in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\layers\\chain.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\layers\\chain.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\layers\\chain.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\layers\\with_array.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSeqT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeqT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXseq\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSeqT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXseq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRagged\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         return _ragged_forward(\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mRagged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRagged\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRagged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\layers\\with_array.py\u001b[0m in \u001b[0;36m_ragged_forward\u001b[1;34m(model, Xr, is_train)\u001b[0m\n\u001b[0;32m     88\u001b[0m ) -> Tuple[Ragged, Callable]:\n\u001b[0;32m     89\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mArrayXd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mArrayXd\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_dX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataXd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdYr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mRagged\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mRagged\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\layers\\concatenate.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mInT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mYs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_list_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\layers\\concatenate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mInT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mYs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_list_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\layers\\chain.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \"\"\"Call the model's `forward` function, returning the output and a\n\u001b[0;32m    290\u001b[0m         callback to compute the gradients via backpropagation.\"\"\"\n\u001b[1;32m--> 291\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mInT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mOutT\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"Model\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\thinc\\layers\\hashembed.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(model, ids, is_train)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mseed\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"seed\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[0mdrop_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(analyzer=spacy_nlp_tokenizer, min_df=5)\n",
    "\n",
    "X_train_tok = vect.fit_transform(X_train)\n",
    "\n",
    "X_test_tok = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tok.shape, X_test_tok.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('x_train_tok.pkl','wb') as outfile:\n",
    "    pickle.dump(X_train_tok,outfile)\n",
    "with open('x_test_tok.pkl','wb') as outfile:\n",
    "    pickle.dump(X_test_tok,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "infile = open('x_train_tok.pkl','rb')\n",
    "X_train_tok = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "infile = open('x_test_tok.pkl','rb')\n",
    "X_test_tok = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21029, 6806178), (7010, 6806178))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tok.shape, X_test_tok.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'sel__k': [1000, 2000, 5000, 10000], 'learner__C': [0.01, 0.1, 1, 10]},\n",
    " ]\n",
    "\n",
    "opt_pipeline = Pipeline([\n",
    "    ('sel', SelectKBest(chi2)),  # feature selection\n",
    "    ('tfidf', TfidfTransformer()),  # weighting\n",
    "    ('learner', LinearSVC())  # learning algorithm\n",
    "])\n",
    "\n",
    "\n",
    "n_jobs = 2\n",
    "\n",
    "opt_search = GridSearchCV(opt_pipeline, param_grid, cv=5, n_jobs = n_jobs, verbose=3).fit(X_train_tok,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2905848787446505\n"
     ]
    }
   ],
   "source": [
    "opt_predictions = opt_search.best_estimator_.predict(X_test_tok)\n",
    "\n",
    "correct = 0\n",
    "for prediction,true_label in zip(opt_predictions, y_test):\n",
    "    if prediction==true_label:\n",
    "        correct += 1\n",
    "print(correct/len(opt_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "         action       0.00      0.00      0.00       516\n",
      "      adventure       0.00      0.00      0.00       166\n",
      "      animation       0.00      0.00      0.00       205\n",
      "           arts       0.00      0.00      0.00        18\n",
      "      biography       0.00      0.00      0.00        55\n",
      "         comedy       0.24      0.02      0.04      1636\n",
      "    documentary       0.00      0.00      0.00        23\n",
      "          drama       0.29      0.98      0.45      2041\n",
      "         family       0.00      0.00      0.00        81\n",
      "        fantasy       0.00      0.00      0.00        78\n",
      "        fiction       0.00      0.00      0.00       117\n",
      "     historical       0.00      0.00      0.00        63\n",
      "         horror       0.00      0.00      0.00       342\n",
      "        musical       0.00      0.00      0.00       139\n",
      "           noir       0.00      0.00      0.00        86\n",
      "        romance       0.00      0.00      0.00       335\n",
      "science fiction       0.00      0.00      0.00        78\n",
      "         serial       0.00      0.00      0.00        20\n",
      "         social       0.00      0.00      0.00        28\n",
      "          sport       0.00      0.00      0.00        15\n",
      "       thriller       0.00      0.00      0.00       634\n",
      "            war       0.00      0.00      0.00       105\n",
      "        western       0.00      0.00      0.00       229\n",
      "\n",
      "       accuracy                           0.29      7010\n",
      "      macro avg       0.02      0.04      0.02      7010\n",
      "   weighted avg       0.14      0.29      0.14      7010\n",
      "\n",
      "Confusion matrix:\n",
      "[[   0    0    0    0    0    6    0  510    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    3    0  163    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    6    0  199    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0   18    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    1    0   54    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0   31    0 1605    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0   23    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0   35    0 2006    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0   81    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    4    0   74    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    2    0  115    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    3    0   60    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    5    0  337    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    3    0  136    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    1    0   85    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    1    0  334    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    2    0   76    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    1    0   19    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    1    0   27    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    1    0   14    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0   11    0  623    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    4    0  101    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    6    0  223    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacopo\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jacopo\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jacopo\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, opt_predictions))\n",
    "print('Confusion matrix:')\n",
    "cm = confusion_matrix(y_test, opt_predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
