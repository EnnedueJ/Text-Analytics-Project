{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Dataframe and libraries Import","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\nfrom tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\n\n# Or only check for gpu's with cuda support\nphysical_devices = tf.config.list_physical_devices('GPU') \ntf.config.experimental.set_memory_growth(physical_devices[0], True)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:17:09.828218Z","iopub.execute_input":"2021-12-11T15:17:09.828567Z","iopub.status.idle":"2021-12-11T15:17:15.902677Z","shell.execute_reply.started":"2021-12-11T15:17:09.828460Z","shell.execute_reply":"2021-12-11T15:17:15.901878Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"gpus = tf.config.list_physical_devices('GPU')\nif gpus:\n  # Restrict TensorFlow to only use the first GPU\n  try:\n    tf.config.set_visible_devices(gpus[0], 'GPU')\n    logical_gpus = tf.config.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n  except RuntimeError as e:\n    # Visible devices must be set before GPUs have been initialized\n    print(e)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:17:15.904577Z","iopub.execute_input":"2021-12-11T15:17:15.905092Z","iopub.status.idle":"2021-12-11T15:17:15.919073Z","shell.execute_reply.started":"2021-12-11T15:17:15.905052Z","shell.execute_reply":"2021-12-11T15:17:15.918268Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n\ndf = pd.read_csv('../input/movie-classification/movie_dataset_classification.csv',index_col=0)\ndf.dropna(subset=['Plot'], inplace=True)\ndf.drop_duplicates(subset=['Title','Plot'], inplace=True)\n#removing low frequency genres\ncounts = df.Genre.value_counts()\ncounts = list(counts[counts < 150].index)\ndf = df[~df['Genre'].isin(counts)]","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:17:15.920726Z","iopub.execute_input":"2021-12-11T15:17:15.921263Z","iopub.status.idle":"2021-12-11T15:17:18.781605Z","shell.execute_reply.started":"2021-12-11T15:17:15.921225Z","shell.execute_reply":"2021-12-11T15:17:18.780816Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df['Genre'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:17:18.783214Z","iopub.execute_input":"2021-12-11T15:17:18.783445Z","iopub.status.idle":"2021-12-11T15:17:18.800482Z","shell.execute_reply.started":"2021-12-11T15:17:18.783412Z","shell.execute_reply":"2021-12-11T15:17:18.799550Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, SpatialDropout1D\nfrom keras.layers import LSTM\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nmax_features = 5000\nmaxlen = 300\nembedding_dims = 300\nhidden_dims = 20\n\nX = df['Plot'].values","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:26:36.723382Z","iopub.execute_input":"2021-12-11T15:26:36.723650Z","iopub.status.idle":"2021-12-11T15:26:37.271888Z","shell.execute_reply.started":"2021-12-11T15:26:36.723622Z","shell.execute_reply":"2021-12-11T15:26:37.271029Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Building vocabulary with nltk","metadata":{}},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(X)\n\nX = tokenizer.texts_to_sequences(X)\nX = pad_sequences(X, maxlen)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:26:38.387858Z","iopub.execute_input":"2021-12-11T15:26:38.388291Z","iopub.status.idle":"2021-12-11T15:27:05.832183Z","shell.execute_reply.started":"2021-12-11T15:26:38.388255Z","shell.execute_reply":"2021-12-11T15:27:05.831154Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:27:05.834112Z","iopub.execute_input":"2021-12-11T15:27:05.834426Z","iopub.status.idle":"2021-12-11T15:27:06.882884Z","shell.execute_reply.started":"2021-12-11T15:27:05.834378Z","shell.execute_reply":"2021-12-11T15:27:06.882049Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"len(tokenizer.word_index)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:27:06.884348Z","iopub.execute_input":"2021-12-11T15:27:06.884661Z","iopub.status.idle":"2021-12-11T15:27:06.890372Z","shell.execute_reply.started":"2021-12-11T15:27:06.884607Z","shell.execute_reply":"2021-12-11T15:27:06.889562Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from collections import OrderedDict\ndictionary = dict(OrderedDict(sorted(tokenizer.word_counts.items(), key=lambda x: x[1], reverse=True)))","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:27:06.892698Z","iopub.execute_input":"2021-12-11T15:27:06.893033Z","iopub.status.idle":"2021-12-11T15:27:07.117896Z","shell.execute_reply.started":"2021-12-11T15:27:06.892999Z","shell.execute_reply":"2021-12-11T15:27:07.117032Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"vocab = {x:y for i,(x, y) in enumerate(dictionary.items()) if i < max_features-1 }","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:27:07.119010Z","iopub.execute_input":"2021-12-11T15:27:07.119694Z","iopub.status.idle":"2021-12-11T15:27:07.150143Z","shell.execute_reply.started":"2021-12-11T15:27:07.119655Z","shell.execute_reply":"2021-12-11T15:27:07.149168Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"len(vocab)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:27:07.153305Z","iopub.execute_input":"2021-12-11T15:27:07.153577Z","iopub.status.idle":"2021-12-11T15:27:07.162145Z","shell.execute_reply.started":"2021-12-11T15:27:07.153552Z","shell.execute_reply":"2021-12-11T15:27:07.161418Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Embedding","metadata":{}},{"cell_type":"code","source":"glove_emb_link = \"https://huggingface.co/stanfordnlp/glove/resolve/main/glove.6B.zip\"","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:27:07.163559Z","iopub.execute_input":"2021-12-11T15:27:07.164007Z","iopub.status.idle":"2021-12-11T15:27:07.168668Z","shell.execute_reply.started":"2021-12-11T15:27:07.163971Z","shell.execute_reply":"2021-12-11T15:27:07.167987Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from io import StringIO, BytesIO, TextIOWrapper\nfrom zipfile import ZipFile\nfrom urllib.request import urlopen\nimport requests\n\nresp = requests.get(glove_emb_link)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:27:07.169720Z","iopub.execute_input":"2021-12-11T15:27:07.170300Z","iopub.status.idle":"2021-12-11T15:27:24.786760Z","shell.execute_reply.started":"2021-12-11T15:27:07.170263Z","shell.execute_reply":"2021-12-11T15:27:24.785949Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"embeddings_index = dict()\n\nwith ZipFile(BytesIO(resp.content),'r') as zipfile:\n    with TextIOWrapper(zipfile.open(\"glove.6B.300d.txt\"), encoding=\"utf-8\") as file:\n        for line in file:\n            values = line.split()\n            word = values[0]\n            coefs = np.asarray(values[1:], dtype='float32')\n            embeddings_index[word] = coefs\n\nprint('Loaded %s word vectors.' % len(embeddings_index))","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:27:24.790471Z","iopub.execute_input":"2021-12-11T15:27:24.790725Z","iopub.status.idle":"2021-12-11T15:28:17.369296Z","shell.execute_reply.started":"2021-12-11T15:27:24.790696Z","shell.execute_reply":"2021-12-11T15:28:17.368558Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# create a weight matrix for words in training docs\nembedding_matrix = np.zeros((max_features, embedding_dims))\nfor word in vocab.keys():\n    i = tokenizer.word_index[word]\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:28:17.371859Z","iopub.execute_input":"2021-12-11T15:28:17.372609Z","iopub.status.idle":"2021-12-11T15:28:17.397777Z","shell.execute_reply.started":"2021-12-11T15:28:17.372570Z","shell.execute_reply":"2021-12-11T15:28:17.397128Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"len(embedding_matrix)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:28:17.398866Z","iopub.execute_input":"2021-12-11T15:28:17.399128Z","iopub.status.idle":"2021-12-11T15:28:17.404638Z","shell.execute_reply.started":"2021-12-11T15:28:17.399093Z","shell.execute_reply":"2021-12-11T15:28:17.403923Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"resp = None","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:28:17.406010Z","iopub.execute_input":"2021-12-11T15:28:17.406482Z","iopub.status.idle":"2021-12-11T15:28:17.414757Z","shell.execute_reply.started":"2021-12-11T15:28:17.406446Z","shell.execute_reply":"2021-12-11T15:28:17.413954Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Classification","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\n\ny = np.array(df['Genre'].values)\nn_labels = len(set(y))\n\nlabel_encoder = LabelEncoder()\ny = np.array(label_encoder.fit_transform(y))\n\ncat_y = to_categorical(y, num_classes=n_labels)\n\nX_train, X_test, y_train, y_test = train_test_split(X, cat_y, test_size=0.30, stratify=y, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:33:40.891612Z","iopub.execute_input":"2021-12-11T15:33:40.891879Z","iopub.status.idle":"2021-12-11T15:33:40.958601Z","shell.execute_reply.started":"2021-12-11T15:33:40.891851Z","shell.execute_reply":"2021-12-11T15:33:40.957838Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"import numpy as np \n\nsample_idx = 0\ny_train_bin = np.asarray(y_train)==y_train[sample_idx]\ny_test_bin = np.asarray(y_test)==y_train[sample_idx]\ny_train_bin,y_test_bin","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom keras.initializers import Constant\n\ne = Embedding(max_features,\n              embedding_dims, \n              weights=[embedding_matrix], \n              input_length=maxlen, \n              trainable=False)\n\nmodel = Sequential()\nmodel.add(e)\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(LSTM(hidden_dims, dropout=0.3))\nmodel.add(Dense(n_labels, activation='softmax'))\n\nopt = Adam(learning_rate=0.01)\n\n# try using different optimizers and different optimizer configs\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=opt,\n              metrics=['accuracy'])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:28:17.988875Z","iopub.execute_input":"2021-12-11T15:28:17.989142Z","iopub.status.idle":"2021-12-11T15:28:18.827170Z","shell.execute_reply.started":"2021-12-11T15:28:17.989110Z","shell.execute_reply":"2021-12-11T15:28:18.826454Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"batch_size = 1024\nepochs = 100\nprint('Train...')\nmodel.fit(X_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          shuffle=True,\n          validation_split=0.15)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-12-11T15:28:18.828306Z","iopub.execute_input":"2021-12-11T15:28:18.828587Z","iopub.status.idle":"2021-12-11T15:30:42.250083Z","shell.execute_reply.started":"2021-12-11T15:28:18.828550Z","shell.execute_reply":"2021-12-11T15:30:42.249353Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\ny_preds = model.predict(X_test)\nprediction = np.argmax(y_preds,axis=1)\nground_truth = np.argmax(y_test, axis=1)\naccuracy_score(ground_truth,prediction)","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:37:11.309722Z","iopub.execute_input":"2021-12-11T15:37:11.310302Z","iopub.status.idle":"2021-12-11T15:37:12.937656Z","shell.execute_reply.started":"2021-12-11T15:37:11.310268Z","shell.execute_reply":"2021-12-11T15:37:12.937019Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1,1,figsize=(15, 10))\ncm = confusion_matrix(ground_truth, prediction, labels=list(set(ground_truth)))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=label_encoder.classes_)\ndisp.plot(ax=ax, xticks_rotation='vertical')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-11T15:46:29.014613Z","iopub.execute_input":"2021-12-11T15:46:29.015318Z","iopub.status.idle":"2021-12-11T15:46:30.387827Z","shell.execute_reply.started":"2021-12-11T15:46:29.015280Z","shell.execute_reply":"2021-12-11T15:46:30.387150Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}